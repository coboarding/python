version: '3.8'

services:
  llm-orchestrator-min:
    build:
      context: ./containers/llm-orchestrator-min
      args:
    container_name: llm-orchestrator-min
    volumes:
      - ./volumes/models:/app/models
      - ./volumes/config:/app/config
      - pip-cache:/root/.cache/pip
    environment:
      - USE_INT8=true
      - PYTHONUNBUFFERED=1
      - FLASK_ENV=production
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    restart: unless-stopped
    ports:
      - "5000:5000"  # API LLM
    networks:
      - autoformfiller-min-network

  browser-service:
    build:
      context: ./containers/browser-service
      args:
    container_name: browser-service
    volumes:
      - ./volumes/recordings:/app/recordings
      - pip-cache:/root/.cache/pip
    environment:
      - DISPLAY=:99
      - PYTHONUNBUFFERED=1
    deploy:
      resources:
        limits:
          memory: 1G
    restart: unless-stopped
    ports:
      - "5900:5900"  # VNC
    networks:
      - autoformfiller-min-network

  novnc:
    build:
      context: ./containers/novnc
      args:
    container_name: novnc
    deploy:
      resources:
        limits:
          memory: 256M
    restart: unless-stopped
    ports:
      - "8080:8080"  # noVNC Web UI
    networks:
      - autoformfiller-min-network
    depends_on:
      - browser-service

networks:
  autoformfiller-min-network:
    driver: bridge

volumes:
  pip-cache:
    name: coboarding-pip-cache
