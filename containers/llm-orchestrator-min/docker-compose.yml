version: '3.8'

services:
  # API Gateway (Traefik)
  api-gateway:
    build: ./microservices/api-gateway
    container_name: llm-api-gateway
    ports:
      - "80:80"      # API
      - "8080:8080"  # Dashboard
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - llm-network
    depends_on:
      - model-service
    restart: unless-stopped

  # Model Service
  model-service:
    build: ./microservices/model-service
    container_name: llm-model-service
    environment:
      - MODEL_PATH=/app/models/tinyllama
      - USE_INT8=true
      - MODEL_SERVICE_PORT=5000
    volumes:
      - model-data:/app/models
    networks:
      - llm-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G

  # Cache Service (można dodać w przyszłości)
  # cache-service:
  #   build: ./microservices/cache-service
  #   container_name: llm-cache-service
  #   networks:
  #     - llm-network
  #   restart: unless-stopped

  # Monitoring Service (można dodać w przyszłości)
  # monitoring-service:
  #   build: ./microservices/monitoring-service
  #   container_name: llm-monitoring-service
  #   networks:
  #     - llm-network
  #   restart: unless-stopped

networks:
  llm-network:
    driver: bridge

volumes:
  model-data:
    driver: local
